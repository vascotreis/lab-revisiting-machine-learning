{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f58e4bff-9c9e-4996-81a9-3e516223f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in numerical data\n",
    "def check_nans(data):\n",
    "    nans = pd.DataFrame(data.isna().sum()).reset_index()\n",
    "    nans.columns = ['count', 'val']\n",
    "    display(nans[nans['val'] > 0])\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ade821-535d-4d60-8d89-02ac5be8dfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>NEXTDATE</td>\n",
       "      <td>9973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count   val\n",
       "316  NEXTDATE  9973"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SOLIH</td>\n",
       "      <td>89212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VETERANS</td>\n",
       "      <td>84986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count    val\n",
       "5     SOLIH  89212\n",
       "6  VETERANS  84986"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set display options for pandas dataframes\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 15)\n",
    "\n",
    "# Load target data\n",
    "y = pd.read_csv('target1.csv')\n",
    "y = y['TARGET_B']\n",
    "\n",
    "# Load numerical and categorical feature data\n",
    "numerical = pd.read_csv('numerical1.csv')\n",
    "categorical = pd.read_csv('categorical1.csv')\n",
    "\n",
    "# Drop unnamed columns\n",
    "numerical = numerical.drop(columns=['Unnamed: 0'])\n",
    "categorical = categorical.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "check_nans(numerical)\n",
    "\n",
    "# Fill NaN values in numerical data\n",
    "numerical['NEXTDATE'] = numerical['NEXTDATE'].fillna(0)\n",
    "\n",
    "# Check for NaN values in categorical data\n",
    "check_nans(categorical)\n",
    "\n",
    "# Fill NaN values in categorical data\n",
    "categorical.SOLIH = categorical.SOLIH.fillna(13)\n",
    "categorical.VETERANS = categorical.VETERANS.fillna('N')\n",
    "\n",
    "# Convert all values in categorical data to string\n",
    "categorical = categorical.applymap(str)\n",
    "\n",
    "# Combine numerical and categorical data into one dataset\n",
    "X = pd.concat([numerical, categorical], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e9fef5d-a3d1-4e52-afae-f3f9c8510c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# Split the data into numeric and categorical\n",
    "X_train_num = X_train.select_dtypes(np.number) \n",
    "X_train_cat = X_train.select_dtypes(object)\n",
    "X_test_num = X_test.select_dtypes(np.number)\n",
    "X_test_cat  = X_test.select_dtypes(object)\n",
    "\n",
    "# Scale the numeric data\n",
    "transformer = MinMaxScaler().fit(X_train_num)\n",
    "X_train_num_scaled = pd.DataFrame(transformer.transform(X_train_num), columns = X_train_num.columns)\n",
    "X_test_num_scaled = pd.DataFrame(transformer.transform(X_test_num), columns = X_test_num.columns)\n",
    "\n",
    "# Encode the categorical data\n",
    "def cat_encode(data, onehotencoder):\n",
    "    encoded = onehotencoder.transform(data).toarray()\n",
    "    cols = onehotencoder.get_feature_names_out(input_features=data.columns)\n",
    "    return pd.DataFrame(encoded, columns=cols).reset_index(drop=True)\n",
    "\n",
    "onehotencoder = OneHotEncoder(drop='first', handle_unknown = 'ignore').fit(X_train_cat)\n",
    "X_train_cat_encoded = cat_encode(X_train_cat, onehotencoder).reset_index(drop = True)\n",
    "X_test_cat_encoded = cat_encode(X_test_cat, onehotencoder).reset_index(drop = True)\n",
    "\n",
    "# Combine the encoded categorical and scaled numeric data\n",
    "X_train_scaled = pd.concat([X_train_cat_encoded, X_train_num_scaled], axis = 1)\n",
    "X_test_scaled = pd.concat([X_test_cat_encoded, X_test_num_scaled], axis = 1)\n",
    "\n",
    "# Reset the index for the target variables\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "\n",
    "# Define the logistic regression model\n",
    "def logistic_regression_model(X, y, X_test):\n",
    "    lr = LogisticRegression(random_state=0, solver='saga', multi_class='multinomial').fit(X, y)\n",
    "    return lr.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24167d5f-d06d-4048-989c-5aa9e0099f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def model_eval(Y, P):\n",
    "    print('\\033[1m' + '\\033[91m' + '      Logistics Regression\\n' + '\\033[0m')\n",
    "    conf_matrix = confusion_matrix(Y, P)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(Y, P))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "089b6ca2-c1fa-41fd-924a-809dac175af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Prepare the data\n",
    "s_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "cat_1 = s_data[s_data['TARGET_B'] == 1]\n",
    "cat_0 = s_data[s_data['TARGET_B'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bd2823e-227a-4036-b827-15168abb67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m      Logistics Regression\n",
      "\u001b[0m\n",
      "Confusion Matrix:\n",
      "[[13226  9426]\n",
      " [  523   678]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.73     22652\n",
      "           1       0.07      0.56      0.12      1201\n",
      "\n",
      "    accuracy                           0.58     23853\n",
      "   macro avg       0.51      0.57      0.42     23853\n",
      "weighted avg       0.92      0.58      0.70     23853\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Downsampling the majority class\n",
    "cat_0_undersampled = resample(cat_0, replace=False, n_samples=len(cat_1))\n",
    "s_data_downsampled = pd.concat([cat_0_undersampled, cat_1], axis=0)\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_down = s_data_downsampled.drop(columns=['TARGET_B'])\n",
    "y_down = s_data_downsampled['TARGET_B']\n",
    "\n",
    "# Predict target variable for X_test_scaled\n",
    "predicted = logistic_regression_model(X_down, y_down, X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "model_eval(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "416a59ad-63c7-47b4-9b7b-ce964f7a4034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m      Logistics Regression\n",
      "\u001b[0m\n",
      "Confusion Matrix:\n",
      "[[14049  8603]\n",
      " [  552   649]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.62      0.75     22652\n",
      "           1       0.07      0.54      0.12      1201\n",
      "\n",
      "    accuracy                           0.62     23853\n",
      "   macro avg       0.52      0.58      0.44     23853\n",
      "weighted avg       0.92      0.62      0.72     23853\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. Upsampling the minority class\n",
    "cat_1_upsampled = resample(cat_1, replace=True, n_samples=len(cat_0))\n",
    "s_data_upsampled = pd.concat([cat_1_upsampled, cat_0], axis=0)\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_up = s_data_upsampled.drop(columns=['TARGET_B'])\n",
    "y_up = s_data_upsampled['TARGET_B']\n",
    "\n",
    "# Predict target variable for X_test_scaled\n",
    "predicted = logistic_regression_model(X_up, y_up, X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "model_eval(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfed531a-8499-4ef5-a187-dcd45e088e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m      Logistics Regression\n",
      "\u001b[0m\n",
      "Confusion Matrix:\n",
      "[[14161  8491]\n",
      " [  593   608]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.63      0.76     22652\n",
      "           1       0.07      0.51      0.12      1201\n",
      "\n",
      "    accuracy                           0.62     23853\n",
      "   macro avg       0.51      0.57      0.44     23853\n",
      "weighted avg       0.91      0.62      0.72     23853\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "X_smote = s_data.drop(columns=['TARGET_B'])\n",
    "y_smote = s_data['TARGET_B']\n",
    "\n",
    "# Use SMOTE to balance the class distribution\n",
    "smote = SMOTE(random_state=100, k_neighbors=3)\n",
    "X_S, y_S = smote.fit_resample(X_smote, y_smote)\n",
    "\n",
    "# Predict target variable for X_test_scaled\n",
    "predicted = logistic_regression_model(X_S, y_S, X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "model_eval(y_test, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
